{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files_needed = [\n",
    "    {\"thinkplot.py\": \"https://github.com/AkeemSemper/ml_data/raw/main/thinkplot.py\"},\n",
    "    {\"thinkstats2.py\": \"https://github.com/AkeemSemper/ml_data/raw/main/thinkstats2.py\"},\n",
    "]\n",
    "current_folder = os.getcwd()\n",
    "for f in files_needed:\n",
    "    for file_name, url in f.items():\n",
    "        if not os.path.exists(file_name):\n",
    "            print(f\"Downloading {file_name}\")\n",
    "            os.system(f\"curl {url} -o {current_folder}/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "from scipy import stats as ss\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quiz 3</h1>\n",
    "\n",
    "Please fill in the bodies of the functions as specified. Please read the instructions closely and ask for clarification if needed. A few notes/tips:\n",
    "<ul>\n",
    "<li>Like all the functions we use, the function is a self contained thing. It takes in values as paramaters when called, and produces a return value. All of the inputs that may change should be in that function call, imagine your function being cut/pasted into some other file - it should not depend on anything outside of libraries that it may need. \n",
    "<li>Test your function with more than one function call, with different inputs. See an example in comments below the first question. \n",
    "<li>If something doesn't work, print or look at the varaibles window. The #1 skill that'll allow you to write usable code is the ability to find and fix errors. Printing a value out line by line so you can see how it changes, and looking for the step where something goes wrong is A-OK and pretty normal. It is boring. \n",
    "<li>Unless otherwise specified, you can use outside library functions to calculate things. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Data</h1>\n",
    "\n",
    "You may notice there's no data specified or attached. You'll need to generate some test data if you want to test your functions. \n",
    "\n",
    "The easiest way to generate test data is to use some of the random functions to generate data that looks like what you need. Numpy random and scipy disributions .rvs functions are good places to look, we've also generated random data many times in the past. \n",
    "\n",
    "There is no specific requirement on what your data needs to be, it just needs to be good enough to test your function. If you pay attention to what exactly you're calculating and the criteria given, you should be able to create some suitable data for different tests. As an example, for the Hyp Test question, you need two sets of normal data. You can generate some in many ways, one is through scipy:\n",
    "<ul>\n",
    "<li>ss.norm.rvs(loc=0, scale=1, size=1, random_state=None)\n",
    "</ul>\n",
    "<p>\n",
    "Since you're checking if there's a significant difference between the two groups, you'd likely want multiple sets of data - two that are very close, so they will not show a difference, and two that are not close, so they will show a difference. Think about what you are checking, then just make some data that will allow you to test that. \n",
    "\n",
    "This should not be extremely difficult to code nor should it be super time consuming, the commands are pretty simple and generating random varaibles is pretty similar for any distribution. There is some though involved in saying \"what data do I need to check this?\" That's something that is pretty important in general, if we are creating something we need to make sure that it works in general, not just one example. Critically, there are not specific sets of data you need - almost anything will work. It is only there to let your functions run and see if they are correct. You don't need to aim for \"the perfect test data\" or anything like that, just make some data in a list, if it needs to be of a certain distribution, use that dist to get it; if the distribution doesn't matter, just make something. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ski on Chi - 10pts</h1>\n",
    "\n",
    "You operate a ski hill, and over the years you've seen the distribution of skiers vs snowboarders vs snow skaters etc... change a bit. This is your first full open season since the pandemic hit. When you closed in early 2020, the distribution of your customer base was:\n",
    "<ul>\n",
    "<li>Skiers - 40%\n",
    "<li>Snowboarders - 20%\n",
    "<li>Snow Skaters - 5%\n",
    "<li>Non-Active (i.e. sit in the lodger) - 15%\n",
    "<li>Lesson takers - 20%\n",
    "</ul>\n",
    "\n",
    "You are seeing a different pattern now, but you are not sure if that is due to a change in what your customers want or due to just random chance. You want to be able to analytically tell if what you observe each week is a real change from that baseline above, or nothing to worry about. \n",
    "\n",
    "In this function you'll take in:\n",
    "<ul>\n",
    "<li>Two list of values for the observed number of customers in each group, in the order indicated above. E.g. [35,25,10,10,20].\n",
    "<li>An alpha value (the cutoff criteria for a p-values)\n",
    "</ul>\n",
    "<br><br>\n",
    "You'll return 3 results:\n",
    "<ul>\n",
    "<li>A true/false assessment for if the data appears to show a significant difference in means, measured by if the pValue is less than the supplied alpha. \n",
    "<li>The name of the category that MOST EXCEEDS the expectation. \n",
    "<li>The name of the cetegory that is MOST EXCEEDED BY the expectation. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skiCustomersChange(observedCustys, alpha=.05):\n",
    "\n",
    "    return isSignificantDiff, higherThanExp, lowerThanExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example function calls\n",
    "#diff, highCategory, lowCategory = skiCustomersChange([35,25,10,10,20], .05)\n",
    "#diff, highCategory, lowCategory = skiCustomersChange([15,40,15,10,20], .1)\n",
    "#diff, highCategory, lowCategory = skiCustomersChange([40,10,10,10,30], .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Test Results\n",
      "\n",
      "Call 1 (Alpha=0.05):\n",
      "  Significant Difference: False\n",
      "  MOST EXCEEDS Expectation: Snowboarders\n",
      "  MOST EXCEEDED BY Expectation: Skiers\n",
      "\n",
      "Call 2 (Alpha=0.1):\n",
      "  Significant Difference: True\n",
      "  MOST EXCEEDS Expectation: Snowboarders\n",
      "  MOST EXCEEDED BY Expectation: Skiers\n",
      "\n",
      "Call 3 (Alpha=0.01):\n",
      "  Significant Difference: True\n",
      "  MOST EXCEEDS Expectation: Lesson takers\n",
      "  MOST EXCEEDED BY Expectation: Snowboarders\n"
     ]
    }
   ],
   "source": [
    "#I used the given example function calls...\n",
    "\n",
    "def skiCustomersChange(observedCustys, alpha=.05): #used 5% based on our class discussion\n",
    "\n",
    "    # 1. Define Historical Baseline and Category Names\n",
    "    # Historical proportions: [Skiers, Snowboarders, Snow Skaters, Non-Active, Lesson takers]\n",
    "    historical_props = np.array([0.40, 0.20, 0.05, 0.15, 0.20])\n",
    "    category_names = [\n",
    "        \"Skiers\", \n",
    "        \"Snowboarders\", \n",
    "        \"Snow Skaters\", \n",
    "        \"Non-Active (i.e. sit in the lodger)\", \n",
    "        \"Lesson takers\"\n",
    "    ]\n",
    "    \n",
    "    observed_array = np.array(observedCustys)\n",
    "    total_customers = np.sum(observed_array)\n",
    "\n",
    "    # 2. Calculate Expected Frequencies\n",
    "    expected_array = total_customers * historical_props\n",
    "\n",
    "    # 3. Perform the Chi-Squared Test\n",
    "    # The chisquare function calculates the chi-squared statistic and the p-value.\n",
    "    try:\n",
    "        chi2_stat, p_value = chisquare(f_obs=observed_array, f_exp=expected_array)\n",
    "    except ValueError as e:\n",
    "        # Handle cases where observed/expected counts are zero\n",
    "        print(f\"Error during Chi-Square calculation: {e}. Returning False/N/A.\")\n",
    "        return False, \"N/A\", \"N/A\"\n",
    "\n",
    "    # 4. Determine Significance (p-value < alpha)\n",
    "    isSignificantDiff = p_value < alpha\n",
    "\n",
    "    # 5. Determine Categories with Most Deviation\n",
    "    # Calculate the raw difference: (Observed - Expected)\n",
    "    difference = observed_array - expected_array\n",
    "\n",
    "    # Find the category that MOST EXCEEDS the expectation (largest positive difference)\n",
    "    max_exceed_index = np.argmax(difference)\n",
    "    higherThanExp = category_names[max_exceed_index]\n",
    "\n",
    "    # Find the category that is MOST EXCEEDED BY the expectation (largest negative difference)\n",
    "    min_exceed_index = np.argmin(difference)\n",
    "    lowerThanExp = category_names[min_exceed_index]\n",
    "\n",
    "    return isSignificantDiff, higherThanExp, lowerThanExp\n",
    "\n",
    "# --- Example Function Calls and Printing ---\n",
    "\n",
    "print(\"Chi-Squared Test Results\\n\")\n",
    "\n",
    "# Example 1: [35,25,10,10,20], alpha = .05\n",
    "diff1, highCategory1, lowCategory1 = skiCustomersChange([35,25,10,10,20], .05)\n",
    "print(f\"Call 1 (Alpha=0.05):\")\n",
    "print(f\"  Significant Difference: {diff1}\")\n",
    "print(f\"  MOST EXCEEDS Expectation: {highCategory1}\")\n",
    "print(f\"  MOST EXCEEDED BY Expectation: {lowCategory1}\\n\")\n",
    "\n",
    "# Example 2: [15,40,15,10,20], alpha = .1\n",
    "diff2, highCategory2, lowCategory2 = skiCustomersChange([15,40,15,10,20], .1)\n",
    "print(f\"Call 2 (Alpha=0.1):\")\n",
    "print(f\"  Significant Difference: {diff2}\")\n",
    "print(f\"  MOST EXCEEDS Expectation: {highCategory2}\")\n",
    "print(f\"  MOST EXCEEDED BY Expectation: {lowCategory2}\\n\")\n",
    "\n",
    "# Example 3: [40,10,10,10,30], alpha = .01\n",
    "diff3, highCategory3, lowCategory3 = skiCustomersChange([40,10,10,10,30], .01)\n",
    "print(f\"Call 3 (Alpha=0.01):\")\n",
    "print(f\"  Significant Difference: {diff3}\")\n",
    "print(f\"  MOST EXCEEDS Expectation: {highCategory3}\")\n",
    "print(f\"  MOST EXCEEDED BY Expectation: {lowCategory3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hypothesis Testing - 10pts</h2>\n",
    "\n",
    "In this function you'll take in:\n",
    "<ul>\n",
    "<li>Two list of values - dataA and dataB. The data will be normally distributed. \n",
    "<li>An alpha value (the cutoff criteria for a p-values)\n",
    "<li>A power value (the likelihood of not getting a false negative)\n",
    "<li>An effect size value.\n",
    "</ul>\n",
    "<br><br>\n",
    "You'll produce a tuple of 3 results:\n",
    "<ul>\n",
    "<li>A true/false assessment for if the data appears to show a significant difference in means, measured by if the pValue is less than the supplied alpha in a t-test.\n",
    "<li>A true/false assessment for if a hypothesis test has enough power to be reliable, measured by if the power you calculate is greater than the supplied power. \n",
    "<li>A true false assessment for if the data appears to show a significant difference in means, measured by if the Cohen effect size is greater than the supplied effect size. \n",
    "</ul>\n",
    "\n",
    "<b>Please report your responses in the format indicated in the template. As well, please report all true/false values as 1/0. 1 is True, 0 is false. To verify if all the criteria are true, someone calling this function should be able to multiply the 3 values in the tuple together and get a result of 1 if they are all true, and 0 otherwise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strengthOfEffect(dataA, dataB, alpha=.05, power=.8, effectSize=.5):\n",
    "\n",
    "    results = (passedPtest, passedPower, passedEffectSize)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example function calls\n",
    "# results = strengthOfEffect(oneListOfValues, anotherListOfValues, .05, .9, .7)\n",
    "# results = strengthOfEffect(secondListOfValues, anotherListOfValues, .03, .7, .4)\n",
    "# results = strengthOfEffect(oneListOfValues, moreListOfValues, .05, .8, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Hypothesis Testing Results (1=True, 0=False)\n",
      "\n",
      "Call 1 Results (alpha=0.05, power=0.9, effect=0.7): (1, 1, 1)\n",
      "  Overall Check (Product): 1\n",
      "\n",
      "Call 2 Results (alpha=0.03, power=0.7, effect=0.4): (1, 1, 1)\n",
      "  Overall Check (Product): 1\n",
      "\n",
      "Call 3 Results (alpha=0.05, power=0.8, effect=0.7): (1, 1, 1)\n",
      "  Overall Check (Product): 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def strengthOfEffect(dataA, dataB, alpha=.05, power=.8, effectSize=.5):\n",
    "\n",
    "    arrayA = np.array(dataA)\n",
    "    arrayB = np.array(dataB)\n",
    "    n1 = len(arrayA)\n",
    "    n2 = len(arrayB)\n",
    "    \n",
    "    \n",
    "    # Calculate means and variances\n",
    "    meanA = np.mean(arrayA)\n",
    "    meanB = np.mean(arrayB)\n",
    "    varA = np.var(arrayA, ddof=1) # ddof=1 for sample variance\n",
    "    varB = np.var(arrayB, ddof=1)\n",
    "    \n",
    "    # Pooled variance (assuming equal variance, as common in basic t-tests)\n",
    "    s_pooled_sq = ( (n1 - 1) * varA + (n2 - 1) * varB ) / (n1 + n2 - 2)\n",
    "    s_pooled = np.sqrt(s_pooled_sq)\n",
    "    \n",
    "    # Standard Error (SE) for the difference in means\n",
    "    SE_diff = np.sqrt(s_pooled_sq * (1/n1 + 1/n2))\n",
    "    \n",
    "    # t-statistic\n",
    "    t_stat = (meanA - meanB) / SE_diff\n",
    "    \n",
    "    # Degrees of Freedom\n",
    "    df = n1 + n2 - 2\n",
    "\n",
    "    # Calculate p-value: (1 - CDF of t-distribution for two-sided test)\n",
    "    # We use scipy.stats (ss) here, as calculating the p-value manually \n",
    "    # from the t-distribution integral is not feasible without a library function.\n",
    "    p_value = ss.t.sf(np.abs(t_stat), df) * 2\n",
    "\n",
    "    # Check if pValue is less than the supplied alpha\n",
    "    passedPtest = int(p_value < alpha) # 1 if True, 0 if False\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. Effect Size Assessment (Cohen's d)\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Cohen's d: d = (meanA - meanB) / s_pooled\n",
    "    if s_pooled == 0:\n",
    "        cohen_d = 0\n",
    "    else:\n",
    "        cohen_d = np.abs(meanA - meanB) / s_pooled\n",
    "    \n",
    "    # Check if Cohen effect size is greater than the supplied effectSize cutoff\n",
    "    passedEffectSize = int(cohen_d > effectSize) # 1 if True, 0 if False\n",
    "\n",
    "    # 3. Power Assessment (Manual Calculation)\n",
    "    \n",
    "    # Non-centrality parameter (NCP) under the Alternative Hypothesis (H1)\n",
    "    ncp = cohen_d * np.sqrt((n1 * n2) / (n1 + n2))\n",
    "    \n",
    "    # Calculate the critical t-value (t_crit) for the two-sided test\n",
    "    t_crit = ss.t.ppf(1 - alpha/2, df) \n",
    "    \n",
    "    # Final Calculated Power using ss.nct for a more accurate result:\n",
    "    calculated_power = ss.nct.sf(t_crit, df, ncp) + ss.nct.cdf(-t_crit, df, ncp)\n",
    "\n",
    "    # Check if the calculated power is greater than the supplied power cutoff\n",
    "    passedPower = int(calculated_power > power) # 1 if True, 0 if False\n",
    "\n",
    "    # Final Result\n",
    "    results = (passedPtest, passedPower, passedEffectSize)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Data that is significantly different (high effect)\n",
    "oneListOfValues = [20, 21, 20, 22, 23, 20, 22, 21, 19, 23] # n=10, mean=21.1\n",
    "anotherListOfValues = [30, 31, 30, 32, 33, 30, 32, 31, 29, 33] # n=10, mean=31.1\n",
    "secondListOfValues = [18, 19, 17, 20, 19] # n=5, mean=18.6 (smaller sample size)\n",
    "moreListOfValues = [28, 29, 27, 30, 29] # n=5, mean=28.6 (smaller sample size)\n",
    "\n",
    "print(\"## Hypothesis Testing Results (1=True, 0=False)\\n\")\n",
    "# Example 1: High Diff, Small Alpha/High Power/High Effect -> Should be (1, 1, 1)\n",
    "results1 = strengthOfEffect(oneListOfValues, anotherListOfValues, .05, .9, .7)\n",
    "print(f\"Call 1 Results (alpha=0.05, power=0.9, effect=0.7): {results1}\")\n",
    "print(f\"  Overall Check (Product): {results1[0] * results1[1] * results1[2]}\\n\")\n",
    "\n",
    "# Example 2: Small Samples, High Required Power/Effect -> Might fail power/effect\n",
    "results2 = strengthOfEffect(secondListOfValues, moreListOfValues, .03, .7, .4)\n",
    "print(f\"Call 2 Results (alpha=0.03, power=0.7, effect=0.4): {results2}\")\n",
    "print(f\"  Overall Check (Product): {results2[0] * results2[1] * results2[2]}\\n\")\n",
    "\n",
    "# Example 3: Mixed Sample Sizes, High Required Effect -> Might fail effect\n",
    "results3 = strengthOfEffect(oneListOfValues, moreListOfValues, .05, .8, .7)\n",
    "print(f\"Call 3 Results (alpha=0.05, power=0.8, effect=0.7): {results3}\")\n",
    "print(f\"  Overall Check (Product): {results3[0] * results3[1] * results3[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Safe Test - 10pts</h2>\n",
    "\n",
    "In this function you'll take in:\n",
    "<ul>\n",
    "<li>Two list of values - dataA and dataB.\n",
    "</ul>\n",
    "<br><br>\n",
    "You'll produce a p-value for a two sided hypothesis test:\n",
    "<ul>\n",
    "<li>If the data is not normally distributed, use a Mann-Whitney Test. \n",
    "<li>If the data appears to be normally distributed, and the variance differs substantially, use a Welch's t-test.\n",
    "<li>If none of those conditions are true, use a 'normal' (Student's) t-test. \n",
    "<li>Note: The execution of all of these tests are very similar from your persepective. They are all in the scipy documentation - Google for exact details, and the code closely mirrors the examples we did. \n",
    "<li>Note 2: If you ever need to use a cutoff for a p-value in the middle of your calculations, please choose something reasonable. There are common defaults for whatever you may need. These defaults are likely shown in the documentation or any examples you may look up. \n",
    "</ul>\n",
    "\n",
    "<b>In any case, the value returned is one number (not in a list, tuple, etc...) that is the pValue performed for that test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexHypTest(dataA, dataB):\n",
    "    # Define significance level for screening tests\n",
    "    SCREENING_ALPHA = 0.05\n",
    "    \n",
    "    #1. Check for Normality (Shapiro-Wilk Test) ---\n",
    "\n",
    "    try:\n",
    "        _, p_normA = stats.shapiro(dataA)\n",
    "        _, p_normB = stats.shapiro(dataB)\n",
    "        \n",
    "        # Data is considered normal only if BOTH samples pass the test (p >= SCREENING_ALPHA)\n",
    "        is_normal = (p_normA >= SCREENING_ALPHA) and (p_normB >= SCREENING_ALPHA)\n",
    "    except ValueError:\n",
    "        # If samples are too small for Shapiro-Wilk, assume non-normality for safety\n",
    "        is_normal = False\n",
    "\n",
    "\n",
    "    # --- Decision Path 1: Non-Normal Data ---\n",
    "    if not is_normal:\n",
    "        # Use the Mann-Whitney U Test (non-parametric test for location difference).\n",
    "        pValue = stats.mannwhitneyu(dataA, dataB, alternative='two-sided').pvalue\n",
    "        return pValue\n",
    "\n",
    "    #2. Check for Equal Variance (Levene Test) ---\n",
    "    # Only execute if the data is deemed normal.\n",
    "    \n",
    "    # Use the Levene test to check the homogeneity of variances (center='median' is robust).\n",
    "    # H0: Variances are equal.\n",
    "    _, p_levene = stats.levene(dataA, dataB, center='median')\n",
    "    \n",
    "    # If p_levene < SCREENING_ALPHA, we reject H0, meaning variances differ substantially.\n",
    "    variances_differ_substantially = (p_levene < SCREENING_ALPHA)\n",
    "\n",
    "    # --- Decision Path 2: Normal, Unequal Variance ---\n",
    "    if variances_differ_substantially:\n",
    "        # Use Welch's t-test (ttest_ind with equal_var=False).\n",
    "        pValue = stats.ttest_ind(dataA, dataB, equal_var=False).pvalue\n",
    "        return pValue\n",
    "\n",
    "    # --- Decision Path 3: Normal, Equal Variance (The Default Case) ---\n",
    "    else:\n",
    "        # Use Student's t-test (ttest_ind with equal_var=True).\n",
    "        pValue = stats.ttest_ind(dataA, dataB, equal_var=True).pvalue\n",
    "        return pValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Grade Distribution - 10pts</h1>\n",
    "\n",
    "Grade distributions for final letter grades at a school are generally skewed towards the higher end of the scale. We can model it with a function below.\n",
    "\n",
    "Percentage grades on individual assignments are often skewnormally distributed. (Note: this is more for curved schools than somewhere like NAIT with hard cutoffs. When I was in school CompSci profs would aim for a 50%-60% raw average to get a normal-ish distribution of marks.)\n",
    "\n",
    "You are seeking to generate a grading system, in two steps:\n",
    "<ul>\n",
    "<li>Use the supplied Weibull distribution in the simpleGenerateLetterGradeBuckets function to generate the distribution of letter grades - A,B,C,D,F. We are a simple school and we only have letters, no plus or minus. \n",
    "<li>\n",
    "<li>Use the function simpleGenerateLetterGradeBuckets to tell you HOW MANY slots there are for each grade. This is done for you in the provided function, you just need to call it and get the results. Please pay attention to the n value for number.\n",
    "<li>Take the supplied raw percentage grades and fit them into those buckets. I.E. if there are 17 slots for an A grade, the 17 highest percentage marks should get an A; if there are then 52 for B, then the next 52 highest get a B, etc...\n",
    "<li><b>You are going to return a list of tuples - the original percentage grade, and the letter grade. E.g. [(72,B), (84,A), etc...]</b>\n",
    "</ul>\n",
    "\n",
    "<br><br>\n",
    "In this function you'll take in:\n",
    "<ul>\n",
    "<li>A list of raw percentage grades, from 0 to 100. E.g. [100,98,24,53,45, etc...]\n",
    "</ul>\n",
    "\n",
    "You'll produce:\n",
    "<ul>\n",
    "<li>A list of tuples. Each tuple is the original percentage grade, and the letter grade. .\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "Note: You'll have to run the function cell down at the bottom first. \n",
    "<br><br>\n",
    "<b>Bonus: The provided function for grade buckets probably isn't the best overall, if you can rewrite it to be better, up to 3 bonus marks. Think about the random factor...</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignLetterGrades(rawPercentageGrades):\n",
    "\n",
    "    return listOfTuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 70, 'B': 162, 'C': 122, 'D': 50, 'F': 19}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for 423 students\n",
    "simpleGenerateLetterGradeBuckets(423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleGenerateLetterGradeBuckets(n=100):\n",
    "\n",
    "    # Define distribution params\n",
    "    c = 1.5\n",
    "    loc = 3\n",
    "    scale = 1.5\n",
    "\n",
    "    #Generate distribution buckets\n",
    "    aGrades = 0\n",
    "    bGrades = 0\n",
    "    cGrades = 0\n",
    "    dGrades = 0\n",
    "    fGrades = 0\n",
    "\n",
    "    #Define cutoffs - count above cut are grade slots. E.g. the number of random results over 3.8 are\n",
    "    #the number of slots for A. The number remaining over 3 are the slots for B, etc...\n",
    "    cuts = [3.7, 2.9, 1.9, .9]\n",
    "    data = 7.2-ss.weibull_min.rvs(c, loc, scale, n)\n",
    "    \n",
    "    # Count the number of slots for each letter grade\n",
    "    for tmp in data:\n",
    "        if tmp > cuts[0]:\n",
    "            aGrades += 1\n",
    "        elif tmp > cuts[1]:\n",
    "            bGrades += 1\n",
    "        elif tmp > cuts[2]:\n",
    "            cGrades += 1\n",
    "        elif tmp > cuts[3]:\n",
    "            dGrades += 1\n",
    "        else:\n",
    "            fGrades += 1\n",
    "            \n",
    "    buckets = {\"A\":aGrades, \"B\":bGrades, \"C\":cGrades, \"D\":dGrades, \"F\":fGrades}\n",
    "    return buckets\n",
    "\n",
    "#ASSIGNMENT FUNCTION\n",
    "\n",
    "def assignLetterGrades(rawPercentageGrades):\n",
    "   \n",
    "    # 1. Determine the total number of students (n)\n",
    "    n = len(rawPercentageGrades)\n",
    "    \n",
    "    # 2. Generate the grade buckets/slots\n",
    "    grade_buckets = simpleGenerateLetterGradeBuckets(n)\n",
    "    \n",
    "    # 3. Prepare the data for assignment\n",
    "    indexed_grades = list(enumerate(rawPercentageGrades)) \n",
    "    \n",
    "    # Sort the list by the percentage grade (element [1] of the tuple) in DESCENDING order\n",
    "    sorted_grades = sorted(indexed_grades, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 4. Assign Letter Grades\n",
    "    \n",
    "    # Initialize the results list, sized to hold all final tuples\n",
    "    final_assignments = [None] * n\n",
    "    \n",
    "    # Define the order of assignment (highest to lowest)\n",
    "    grade_order = [\"A\", \"B\", \"C\", \"D\", \"F\"]\n",
    "    \n",
    "    # The current index in the sorted_grades list\n",
    "    current_idx = 0 \n",
    "    \n",
    "    for grade in grade_order:\n",
    "        # Number of slots available for the current grade\n",
    "        num_slots = grade_buckets[grade]\n",
    "        \n",
    "        # Take the next 'num_slots' highest percentages and assign the current letter grade\n",
    "        for i in range(num_slots):\n",
    "            if current_idx < n:\n",
    "                # Get the original index and the percentage grade\n",
    "                original_index = sorted_grades[current_idx][0]\n",
    "                percentage_grade = sorted_grades[current_idx][1]\n",
    "                \n",
    "                # Store the result (percentage, letter_grade) in the final assignments list \n",
    "                # at the original index position.\n",
    "                final_assignments[original_index] = (percentage_grade, grade)\n",
    "                \n",
    "                current_idx += 1\n",
    "            else:\n",
    "                # Should not happen if buckets sum to n, but safe check\n",
    "                break\n",
    "\n",
    "    # 5. Handle any potential missing assignments (e.g., due to rounding/floating point in original bucket function)\n",
    "    #Step not needed for this problem. But added, just in case.\n",
    "    while current_idx < n:\n",
    "        original_index = sorted_grades[current_idx][0]\n",
    "        percentage_grade = sorted_grades[current_idx][1]\n",
    "        final_assignments[original_index] = (percentage_grade, \"F\") \n",
    "        current_idx += 1\n",
    "        \n",
    "    return final_assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
